BUDDY AI Assistant - Current Implementation Overview
Generated on July 01, 2025 (Updated July 2025)

PROJECT STATUS (as of July 2025):
- Project B.U.D.D.Y. is a cross-platform AI assistant for Mac and iPhone.
- The backend uses open-source LLMs (Ollama) running locally for chat.
- Image generation is handled by a single Hugging Face Space (CPU-based).
- Images are uploaded to Cloudinary for storage and delivery.
- The frontend is a SwiftUI app that communicates with the local backend.
- The backend acts as a proxy, forwarding requests to appropriate services.
- **Voice Input:** Users can speak prompts to BUDDY using the microphone button (speech-to-text).
- **Voice Output:** BUDDY replies are spoken aloud using Apple TTS, with a replay button for each message.
- **iOS Device Support:** App runs on real iPhones (not just simulator), with network config for local backend access.

CURRENT ARCHITECTURE:

1. BACKEND: FastAPI (Python) running locally
   - Acts as a lightweight proxy server
   - Forwards chat requests to local Ollama
   - Forwards image requests to Hugging Face Space
   - Uploads generated images to Cloudinary
   - Runs with 4 workers for parallel requests
   - Must use 0.0.0.0 for iOS device access

2. LLM CHAT: Ollama running locally
   - Uses models like Mistral, TinyLlama, Phi-2
   - Runs on localhost:11434
   - Provides instant, private chat responses
   - No cloud costs or dependencies

3. IMAGE GENERATION: Hugging Face Space
   - Single CPU-based space for image generation
   - URL: https://chiefmaybe-buddy-sd.hf.space/generate
   - Generation time: 5-10 minutes
   - Free tier hosting

4. IMAGE STORAGE: Cloudinary
   - Stores generated images
   - Provides CDN delivery
   - Free tier usage

5. FRONTEND: SwiftUI App
   - iOS and macOS compatible
   - Communicates with local backend (use Mac's local IP for iOS device)
   - Displays chat responses and generated images
   - **Voice Input/Output:** Microphone button for speech-to-text, BUDDY replies spoken aloud, replay button for each message

CURRENT WORKFLOW:

Chat Flow:
- User enters or speaks prompt in SwiftUI app
- Backend forwards to local Ollama
- Ollama generates response
- Response displayed in app and spoken aloud

Image Generation Flow:
- User enters image prompt in SwiftUI app
- Backend forwards to Hugging Face Space
- Space generates image (5-10 minutes)
- Backend uploads image to Cloudinary
- Cloudinary URL returned to app
- Image displayed in app

SETUP REQUIREMENTS:

Local Development:
- MacBook Pro M1 (16GB RAM recommended)
- Python environment with FastAPI
- Ollama installed and running
- Xcode for SwiftUI development
- iPhone (iOS 18+) for device testing

Cloud Services:
- Hugging Face account (free)
- Cloudinary account (free tier)
- Environment variables for Cloudinary credentials

CURRENT STATUS:
- ✅ Local chat pipeline working
- ✅ Cloud image generation working
- ✅ SwiftUI frontend connected
- ✅ Cloudinary integration working
- ✅ Backend proxy functionality working
- ✅ Voice input/output working on iOS device

TECHNICAL SPECIFICATIONS:

Backend (FastAPI):
- Port: 8000
- Workers: 4 (parallel requests)
- Dependencies: FastAPI, requests, cloudinary
- No local ML libraries required
- Must use 0.0.0.0 for iOS device access

Ollama:
- Port: 11434
- Models: Mistral, TinyLlama, Phi-2 (open source)
- Local processing only

Hugging Face Space:
- Runtime: Docker
- Hardware: CPU
- Model: Stable Diffusion v1.4
- Timeout: 33 minutes

Cloudinary:
- Usage: Image storage only
- No transformations or manipulations
- Free tier limits

FRONTEND SPECIFICATIONS:

SwiftUI App:
- Target: iOS and macOS
- Network: Mac's local IP for backend (e.g., http://192.168.1.10:8000)
- Features: Chat interface, image generation, modal display, voice input/output, replay button
- Permissions: Network access for local IP, microphone, and speech recognition (Info.plist)

ENVIRONMENT VARIABLES:
- CLOUDINARY_CLOUD_NAME
- CLOUDINARY_API_KEY
- CLOUDINARY_API_SECRET

DEPLOYMENT NOTES:
- Backend runs locally for development
- Ollama runs locally for chat
- Image generation uses free cloud resources
- No paid cloud services required for current setup
- iOS device must be on same Wi-Fi as Mac

FUTURE CONSIDERATIONS:
- Containerize backend and Ollama with Docker
- Deploy to paid cloud server when ready
- Move environment variables to cloud host
- Update frontend to use cloud API endpoint

This implementation provides a complete, working AI assistant using free and open-source tools with local-first chat, cloud-based image generation, and full voice support on iOS devices.

---

## July 2025 UI & Voice Update
- Animated buddy avatar (bobbing, green glow when thinking)
- Glowing 'please wait while I am thinking...' bubble
- Custom app icon and avatar (droid theme)
- Modern, card-based UI with chat bubbles and image generator
- All assets provided at 1x, 2x, 3x for crisp display
- Voice input/output and replay button for BUDDY messages

## Current Status
- Fully functional chat, image generation, and voice features
- Visually polished, interactive UI 